<!DOCTYPE html>
<!-- saved from url=(0045)http://www.cnblogs.com/hseagle/p/3765207.html -->
<html lang="zh-cn"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园</title>
<link type="text/css" rel="stylesheet" href="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/blog-common.css">
<link id="MainCss" type="text/css" rel="stylesheet" href="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/bundle-LessIsMoreRight.css">
<link type="text/css" rel="stylesheet" href="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/134061.css">
<link title="RSS" type="application/rss+xml" rel="alternate" href="http://www.cnblogs.com/hseagle/rss">
<link title="RSD" type="application/rsd+xml" rel="EditURI" href="http://www.cnblogs.com/hseagle/rsd.xml">
<link type="application/wlwmanifest+xml" rel="wlwmanifest" href="http://www.cnblogs.com/hseagle/wlwmanifest.xml">
<script async="" type="text/javascript" src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/gpt.js"></script><script src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/jquery.js" type="text/javascript"></script>  
<script type="text/javascript">var currentBlogApp = 'hseagle', cb_enable_mathjax=true;</script>
<script src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/blog-common.js" type="text/javascript"></script>
<script src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/pubads_impl_78.js" async=""></script><script type="text/x-mathjax-config;executed=true">MathJax.Hub.Config({
  tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] },
  TeX: { equationNumbers: { autoNumber: ['AMS'], useLabelIds: true } },
  'HTML-CSS': { linebreaks: { automatic: true } },
  SVG: { linebreaks: { automatic: true } }});</script><script type="text/javascript" src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/MathJax.js"></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Hover_Arrow {position: absolute; width: 15px; height: 11px; cursor: pointer}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; color: #666666}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_Menu_Close {position: absolute; width: 31px; height: 31px; top: -15px; left: -15px}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style></head>
<body><div id="MathJax_Message" style="display: none;"></div>
<a name="top"></a>
<!--PageBeginHtml Block Begin-->
<script type="text/javascript" src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/pdfobject.js"></script>
<script src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/highlight.pack.js"></script>
<script>
hljs.configure({tabReplace: '  '});
hljs.initHighlightingOnLoad();
</script>
<!--PageBeginHtml Block End-->

<div id="home">
<div id="header">
	<div id="blogTitle">
		
<!--done-->
<div class="title"><a id="Header1_HeaderTitle" class="headermaintitle" href="http://www.cnblogs.com/hseagle/">富贵有定数，学问则无定数。求一分，便得一分</a></div>
<div class="subtitle">快乐源于简单</div>



		
	</div><!--end: blogTitle 博客的标题和副标题 -->
	<div id="navigator">
		
<ul id="navList">
<li id="nav_sitehome"><a id="MyLinks1_HomeLink" class="menu" href="http://www.cnblogs.com/">博客园</a></li>
<li id="nav_myhome"><a id="MyLinks1_MyHomeLink" class="menu" href="http://www.cnblogs.com/hseagle/">首页</a></li>
<li id="nav_q"><a class="menu" href="http://q.cnblogs.com/">博问</a></li>
<li id="nav_ing"><a class="menu" href="http://home.cnblogs.com/ing/">闪存</a></li>
<li id="nav_newpost"><a id="MyLinks1_NewPostLink" class="menu" rel="nofollow" href="http://i.cnblogs.com/EditPosts.aspx?opt=1">新随笔</a></li>
<li id="nav_contact"></li>
<li id="nav_rss"><a id="MyLinks1_Syndication" class="menu" href="http://www.cnblogs.com/hseagle/rss">订阅</a>
<!--<a id="MyLinks1_XMLLink" class="aHeaderXML" href="http://www.cnblogs.com/hseagle/rss"><img src="http://www.cnblogs.com/images/xml.gif" alt="订阅" /></a>--></li>
<li id="nav_admin"><a id="MyLinks1_Admin" class="menu" rel="nofollow" href="http://i.cnblogs.com/">管理</a></li>
</ul>

		<div class="blogStats">
			
			
<!--done-->
随笔-76&nbsp;
文章-0&nbsp;
评论-47&nbsp;

			
		</div><!--end: blogStats -->
	</div><!--end: navigator 博客导航栏 -->
</div><!--end: header 头部 -->
<div id="main">
	<div id="mainContent">
	<div class="forFlow">
		
<div id="post_detail">
<!--done-->
<div id="topics">
	<div class="post">
		<h1 class="postTitle">
			<a id="cb_post_title_url" class="postTitle2" href="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园.html">Apache Spark源码走读之13 -- hiveql on spark实现详解</a>
		</h1>
		<div class="clear"></div>
		<div class="postBody">
			<div id="cnblogs_post_body"><p><em><span style="color: cornflowerblue;"><strong>欢迎转载，转载请注明出处，徽沪一郎</strong></span></em></p>
<h1>概要</h1>
<p>在新近发布的spark 1.0中新加了sql的模块，更为引人注意的是对hive中的hiveql也提供了良好的支持，作为一个源码分析控，了解一下spark是如何完成对hql的支持是一件非常有趣的事情。</p>
<h1>Hive简介</h1>
<h2>Hive的由来</h2>
<p>以下部分摘自Hadoop definite guide中的Hive一章</p>
<p>“<em>Hive由Facebook出品，其设计之初目的是让精通SQL技能的分析师能够对Facebook存放在HDFS上的大规模数据集进行分析和查询。</em></p>
<p><em>Hive大大简化了对大规模数据集的分析门槛（不再要求分析人员具有很强的编程能力），迅速流行起来，成为Hadoop生成圈上的<strong>Killer Application</strong>. 目前已经有很多组织把Hive作为一个通用的，可伸缩数据处理平台。</em>”</p>
<h2>数据模型(Data Model)</h2>
<p>Hive所有的数据都存在HDFS中，在Hive中有以下几种数据模型</p>
<ul>
<li><strong>Tables(表)</strong> table和关系型数据库中的表是相对应的，每个表都有一个对应的hdfs目录，表中的数据经<strong>序列化</strong>后存储在该目录，Hive同时支持表中的数据存储在其它类型的文件系统中，如NFS或本地文件系统</li>
<li><strong>分区(Partitions)</strong> Hive中的分区起到的作用有点类似于RDBMS中的索引功能，每个Partition都有一个对应的目录，这样在查询的时候，可以减少数据规模</li>
<li><strong>桶(buckets)</strong> 即使将数据按分区之后，每个分区的规模有可能还是很大，这个时候，按照关键字的hash结果将数据分成多个buckets，每个bucket对应于一个文件</li>
</ul>
<h2>Query Language</h2>
<p>&nbsp;HiveQL是Hive支持的类似于SQL的查询语言。HiveQL大体可以分成下面两种类型</p>
<ol>
<li><strong>DDL(data definition language)</strong>&nbsp; 比如创建数据库(create database),创建表(create table),数据库和表的删除</li>
<li><strong>DML(data manipulation language)</strong> 数据的添加，查询</li>
<li><strong>UDF(user defined function)</strong> Hive还支持用户自定义查询函数</li>
</ol>
<h2>Hive architecture</h2>
<p>hive的整体框架图如下图所示</p>
<p>&nbsp;<img style="display: block; margin-left: auto; margin-right: auto;" src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/032126369276759.jpg" alt="" width="570" height="767"></p>
<p>由上图可以看出，Hive的整体架构可以分成以下几大部分</p>
<ol>
<li>用户接口&nbsp; 支持CLI, JDBC和Web UI</li>
<li>Driver Driver负责将用户指令翻译转换成为相应的MapReduce Job</li>
<li>MetaStore 元数据存储仓库，像数据库和表的定义这些内容就属于元数据这个范畴，默认使用的是Derby存储引擎</li>
</ol>
<h2>HiveQL执行过程</h2>
<p>HiveQL的执行过程如下所述</p>
<ol>
<li>parser 将HiveQL解析为相应的语法树</li>
<li>Semantic Analyser 语义分析</li>
<li>Logical Plan Generating 生成相应的LogicalPlan</li>
<li>Query Plan Generating</li>
<li>Optimizer</li>
</ol>
<p>最终生成MapReduce的Job，交付给Hadoop的MapReduce计算框架具体运行。</p>
<h2>Hive实例</h2>
<p>最好的学习就是实战，Hive这一小节还是以一个具体的例子来结束吧。</p>
<p>前提条件是已经安装好hadoop，具体安装可以参考源码走读11或走读9</p>
<h3>step 1： 创建warehouse</h3>
<p>warehouse用来存储raw data</p>
<pre><code class="bash hljs ">$ <span class="hljs-variable">$HADOOP_HOME</span>/bin/hadoop fs -mkdir       /tmp
$ <span class="hljs-variable">$HADOOP_HOME</span>/bin/hadoop fs -mkdir       /user/hive/warehouse
$ <span class="hljs-variable">$HADOOP_HOME</span>/bin/hadoop fs -chmod g+w   /tmp
$ <span class="hljs-variable">$HADOOP_HOME</span>/bin/hadoop fs -chmod g+w   /user/hive/warehouse
</code></pre>
<h3>step 2: 启动hive cli</h3>
<pre><code class="bash hljs ">$ <span class="hljs-keyword">export</span> HIVE_HOME=&lt;hive-install-dir&gt;
$ <span class="hljs-variable">$HIVE_HOME</span>/bin/hive
</code></pre>
<h3>step 3: 创建表</h3>
<p>创建表，首先将<strong>schema</strong>数据写入到<strong>metastore</strong>,另一件事情就是在warehouse目录下创建相应的子目录，该子目录以表的名称命名</p>
<pre><code class="sql hljs "><span class="hljs-operator"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> u_data (
  userid <span class="hljs-keyword">INT</span>,
  movieid <span class="hljs-keyword">INT</span>,
  rating <span class="hljs-keyword">INT</span>,
  unixtime STRING)
<span class="hljs-keyword">ROW</span> FORMAT DELIMITED
FIELDS TERMINATED <span class="hljs-keyword">BY</span> <span class="hljs-string">'\t'</span>
STORED <span class="hljs-keyword">AS</span> TEXTFILE;</span>
</code></pre>
<h3>step 4: 导入数据</h3>
<p>导入的数据会存储在step 3中创建的表目录下</p>
<pre><code class="sql hljs "><span class="hljs-operator"><span class="hljs-keyword">LOAD</span> DATA <span class="hljs-keyword">LOCAL</span> INPATH <span class="hljs-string">'/u.data'</span>
OVERWRITE <span class="hljs-keyword">INTO</span> <span class="hljs-keyword">TABLE</span> u_data;</span>
</code></pre>
<h3>step 5: 查询</h3>
<pre><code class="sql hljs "><span class="hljs-operator"><span class="hljs-keyword">SELECT</span> <span class="hljs-aggregate">COUNT</span>(*) <span class="hljs-keyword">FROM</span> u_data;</span>
</code></pre>
<h1>&nbsp;<span style="font-size: 2em; line-height: 1.5;">hiveql on Spark</span></h1>
<p><strong>Q:</strong> 上一章节花了大量的篇幅介绍了hive由来，框架及hiveql执行过程。那这些东西跟我们标题中所称的hive on spark有什么关系呢？</p>
<p><strong>Ans:&nbsp; </strong>Hive的整体解决方案很不错，但有一些地方还值得改进，其中之一就是“<span style="color: #ff0000;"><strong>从查询提交到结果返回需要相当长的时间，查询耗时太长</strong></span>”<strong>。</strong>之所以查询时间很长，一个主要的原因就是因为Hive原生是基于MapReduce的，哪有没有办法提高呢。您一定想到了，“<span style="color: #ff9900;"><strong>不是生成MapReduce Job，而是生成Spark Job</strong></span>”, 充分利用Spark的快速执行能力来缩短HiveQl的响应时间。</p>
<p>下图是Spark 1.0中所支持的lib库，SQL是其唯一新添加的lib库，可见SQL在Spark 1.0中的地位之重要。</p>
<p><img style="display: block; margin-left: auto; margin-right: auto;" src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/041055085367623.png" alt=""></p>
<p>&nbsp;</p>
<h2><span style="font-size: 1.5em; line-height: 1.5;">HiveContext</span></h2>
<p><span style="line-height: 1.5;">HiveContext是Spark提供的用户接口，HiveContext继承自SqlContext。</span></p>
<p><span style="line-height: 1.5;">让我们回顾一下，SqlContext中牵涉到的类及其间的关系如下图所示,具体分析过程参见本系列中的<a href="http://www.cnblogs.com/hseagle/p/3752917.html">源码走读之11</a>。</span></p>
<p><span style="line-height: 1.5;"><img style="display: block; margin-left: auto; margin-right: auto;" src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/271444453061825.png" alt=""></span></p>
<p><span style="line-height: 1.5;">既然是继承自SqlContext，那么我们将普通sql与hiveql分析执行步骤做一个对比，可以得到下图。</span></p>
<p><span style="line-height: 1.5;"><img style="display: block; margin-left: auto; margin-right: auto;" src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/032221051925786.png" alt=""></span></p>
<p>&nbsp;</p>
<p><span style="line-height: 1.5;">有了上述的比较，就能抓住源码分析时需要把握的几个关键点</span></p>
<ol>
<li>Entrypoint&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; HiveContext.scala</li>
<li>QueryExecution&nbsp;&nbsp;&nbsp; HiveContext.scala<br><ol>
<li>parser&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; HiveQl.scala </li>
<li>optimizer &nbsp;&nbsp;&nbsp; </li>

































</ol></li>

































</ol>
<h2>数据</h2>
<p>使用到的数据有两种</p>
<ol>
<li>Schema Data&nbsp; 像数据库的定义和表的结构，这些都存储在MetaStore中</li>
<li>Raw data&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 即要分析的文件本身</li>


























</ol>
<h2>Entrypoint</h2>
<p>hiveql是整个的入口点，而hql是hiveql的缩写形式。</p>
<pre><code class="scala hljs ">  <span class="hljs-keyword">def</span> hiveql(hqlQuery: String): SchemaRDD = {
    <span class="hljs-keyword">val</span> result = <span class="hljs-keyword">new</span> SchemaRDD(<span class="hljs-keyword">this</span>, HiveQl.parseSql(hqlQuery))
    <span class="hljs-comment">// We force query optimization to happen right away instead of letting it happen lazily like</span>
    <span class="hljs-comment">// when using the query DSL.  This is so DDL commands behave as expected.  This is only</span>
    <span class="hljs-comment">// generates the RDD lineage for DML queries, but does not perform any execution.</span>
    result.queryExecution.toRdd
    result
  }
</code></pre>
<p>上述hiveql的定义与sql的定义几乎一模一样，唯一的不同是sql中使用<strong>parseSql</strong>的结果作为SchemaRDD的入参而hiveql中使用<strong>HiveQl.parseSql</strong>作为SchemaRdd的入参</p>
<h2>HiveQL, parser</h2>
<p>parseSql的函数定义如代码所示，解析过程中将指令分成两大类</p>
<ul>
<li>nativecommand&nbsp;&nbsp;&nbsp;&nbsp; 非select语句，这类语句的特点是执行时间不会因为条件的不同而有很大的差异，基本上都能在较短的时间内完成</li>
<li>非nativecommand&nbsp; 主要是select语句</li>
</ul>
<pre><code class="scala hljs "><span class="hljs-keyword">def</span> parseSql(sql: String): LogicalPlan = {
    <span class="hljs-keyword">try</span> {
      <span class="hljs-keyword">if</span> (sql.toLowerCase.startsWith(<span class="hljs-string">"set"</span>)) {
        NativeCommand(sql)
      } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (sql.toLowerCase.startsWith(<span class="hljs-string">"add jar"</span>)) {
        AddJar(sql.drop(<span class="hljs-number">8</span>))
      } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (sql.toLowerCase.startsWith(<span class="hljs-string">"add file"</span>)) {
        AddFile(sql.drop(<span class="hljs-number">9</span>))
      } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (sql.startsWith(<span class="hljs-string">"dfs"</span>)) {
        DfsCommand(sql)
      } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (sql.startsWith(<span class="hljs-string">"source"</span>)) {
        SourceCommand(sql.split(<span class="hljs-string">" "</span>).toSeq <span class="hljs-keyword">match</span> { <span class="hljs-keyword">case</span> Seq(<span class="hljs-string">"source"</span>, filePath) =&gt; filePath })
      } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (sql.startsWith(<span class="hljs-string">"!"</span>)) {
        ShellCommand(sql.drop(<span class="hljs-number">1</span>))
      } <span class="hljs-keyword">else</span> {
        <span class="hljs-keyword">val</span> tree = getAst(sql)

        <span class="hljs-keyword">if</span> (nativeCommands contains tree.getText) {
          NativeCommand(sql)
        } <span class="hljs-keyword">else</span> {
          nodeToPlan(tree) <span class="hljs-keyword">match</span> {
            <span class="hljs-keyword">case</span> NativePlaceholder =&gt; NativeCommand(sql)
            <span class="hljs-keyword">case</span> other =&gt; other
          }
        }
      }
    } <span class="hljs-keyword">catch</span> {
      <span class="hljs-keyword">case</span> e: Exception =&gt; <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> ParseException(sql, e)
      <span class="hljs-keyword">case</span> e: NotImplementedError =&gt; sys.error(
        s<span class="hljs-string">"""
          |Unsupported language features in query: $sql
          |${dumpTree(getAst(sql))}
        """</span>.stripMargin)
    }
  }	
</code></pre>
<p>哪些指令是nativecommand呢，答案在HiveQl.scala中的<span style="color: #ff0000;"><strong>nativeCommands</strong></span>变量，列表很长，代码就不一一列出。</p>
<p>对于非nativeCommand，最重要的解析函数就是<span style="color: #ff0000;"><strong>nodeToPlan</strong></span></p>
<h2>toRdd</h2>
<p><span style="color: #ff0000;"><strong><span style="line-height: 1.5;">Spark对HiveQL所做的优化主要体现在Query相关的操作，其它的依然使用Hive的原生执行引擎。</span></strong></span></p>
<p>在logicalPlan到physicalPlan的转换过程中，toRdd最关键的元素</p>
<pre><code class="scala hljs "><span class="hljs-keyword">override</span> <span class="hljs-keyword">lazy</span> <span class="hljs-keyword">val</span> toRdd: RDD[Row] =
      analyzed <span class="hljs-keyword">match</span> {
        <span class="hljs-keyword">case</span> NativeCommand(cmd) =&gt;
          <span class="hljs-keyword">val</span> output = runSqlHive(cmd)

          <span class="hljs-keyword">if</span> (output.size == <span class="hljs-number">0</span>) {
            emptyResult
          } <span class="hljs-keyword">else</span> {
            <span class="hljs-keyword">val</span> asRows = output.map(r =&gt; <span class="hljs-keyword">new</span> GenericRow(r.split(<span class="hljs-string">"\t"</span>).asInstanceOf[Array[Any]]))
            sparkContext.parallelize(asRows, <span class="hljs-number">1</span>)
          }
        <span class="hljs-keyword">case</span> _ =&gt;
          executedPlan.execute().map(_.copy())
      }
</code></pre>
<h2>native command的执行流程</h2>
<p>由于native command是一些非耗时的操作，直接使用Hive中原有的exeucte engine来执行即可。这些<strong>command</strong>的执行示意图如下</p>
<p><img style="display: block; margin-left: auto; margin-right: auto;" src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/041522094748036.png" alt=""></p>
<h2>analyzer</h2>
<p>HiveTypeCoercion</p>
<pre><code class="scala hljs "><span class="hljs-keyword">val</span> typeCoercionRules =
    List(PropagateTypes, ConvertNaNs, WidenTypes, PromoteStrings, BooleanComparisons, BooleanCasts,
      StringToIntegralCasts, FunctionArgumentConversion)		
</code></pre>
<h1>optimizer</h1>
<p><strong>PreInsertionCasts</strong>存在的目的就是确保在数据插入执行之前，相应的表已经存在。</p>
<pre><code class="scala hljs "><span class="hljs-keyword">override</span> <span class="hljs-keyword">lazy</span> <span class="hljs-keyword">val</span> optimizedPlan =
      optimizer(catalog.PreInsertionCasts(catalog.CreateTables(analyzed)))</code></pre>
<p>此处要注意的是catalog的用途，catalog是<span style="color: #ff0000;"><strong>HiveMetastoreCatalog</strong></span>的实例。</p>
<p>HiveMetastoreCatalog是Spark中对Hive Metastore访问的wrapper。HiveMetastoreCatalog通过调用相应的<strong>Hive Api</strong>可以获得数据库中的表及表的分区，也可以创建新的表和分区。</p>
<p><img style="display: block; margin-left: auto; margin-right: auto;" src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/040000418955269.png" alt=""></p>
<h4><span style="font-size: 2em; line-height: 1.5;">HiveMetastoreCatalog</span></h4>
<p>HiveMetastoreCatalog中会通过hive client来访问metastore中的元数据，使用了大量的Hive Api。其中包括了广为人知的deSer library。</p>
<p>以CreateTable函数为例说明对Hive Library的依赖。</p>
<pre><code class="scala hljs "><span class="hljs-keyword">def</span> createTable(
      databaseName: String,
      tableName: String,
      schema: Seq[Attribute],
      allowExisting: Boolean = <span class="hljs-keyword">false</span>): Unit = {
    <span class="hljs-keyword">val</span> table = <span class="hljs-keyword">new</span> Table(databaseName, tableName)
    <span class="hljs-keyword">val</span> hiveSchema =
      schema.map(attr =&gt; <span class="hljs-keyword">new</span> FieldSchema(attr.name, toMetastoreType(attr.dataType), <span class="hljs-string">""</span>))
    table.setFields(hiveSchema)

    <span class="hljs-keyword">val</span> sd = <span class="hljs-keyword">new</span> StorageDescriptor()
    table.getTTable.setSd(sd)
    sd.setCols(hiveSchema)

    <span class="hljs-comment">// TODO: THESE ARE ALL DEFAULTS, WE NEED TO PARSE / UNDERSTAND the output specs.</span>
    sd.setCompressed(<span class="hljs-keyword">false</span>)
    sd.setParameters(Map[String, String]())
    sd.setInputFormat(<span class="hljs-string">"org.apache.hadoop.mapred.TextInputFormat"</span>)
    sd.setOutputFormat(<span class="hljs-string">"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat"</span>)
    <span class="hljs-keyword">val</span> serDeInfo = <span class="hljs-keyword">new</span> SerDeInfo()
    serDeInfo.setName(tableName)
    serDeInfo.setSerializationLib(<span class="hljs-string">"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe"</span>)
    serDeInfo.setParameters(Map[String, String]())
    sd.setSerdeInfo(serDeInfo)

    <span class="hljs-keyword">try</span> client.createTable(table) <span class="hljs-keyword">catch</span> {
      <span class="hljs-keyword">case</span> e: org.apache.hadoop.hive.ql.metadata.HiveException
        <span class="hljs-keyword">if</span> e.getCause.isInstanceOf[org.apache.hadoop.hive.metastore.api.AlreadyExistsException] &amp;&amp;
           allowExisting =&gt; <span class="hljs-comment">// Do nothing.</span>
    }
  }
</code></pre>
<h1><span style="font-size: 2em; line-height: 1.5;">实验</span></h1>
<p>结合源码，我们再对一个简单的例子作下说明。</p>
<p>可能你会想，既然spark也支持hql，那么我原先用hive cli创建的数据库和表用spark能不能访问到呢？答案或许会让你很纳闷，<span style="color: #ff0000;"><strong>“在默认的配置下是不行的”。为什么？</strong></span></p>
<p><span style="color: #000000;">Hive中的meta data采用的存储引擎是Derby，该存储引擎只能有一个访问用户。同一时刻只能有一个人访问，即便以同一用户登录访问也不行。针对这个局限，解决方法就是将metastore存储在mysql或者其它可以多用户访问的数据库中。</span></p>
<p><span style="color: #000000;">具体实例</span></p>
<ol>
<li><span style="color: #000000;">创建表</span></li>
<li><span style="color: #000000;">导入数据</span></li>
<li><span style="color: #000000;">查询</span></li>
<li><span style="color: #000000;">删除表</span></li>
</ol>
<p><span style="color: #000000;">在启动spark-shell之前，需要先设置环境变量<strong>HIVE_HOME</strong>和<strong>HADOOP_HOME</strong>.</span></p>
<p><span style="color: #000000;">启动spark-shell之后，执行如下代码</span></p>
<pre><code class="scala hljs "><span class="hljs-keyword">val</span> hiveContext = <span class="hljs-keyword">new</span> org.apache.spark.sql.hive.HiveContext(sc)

<span class="hljs-comment">// Importing the SQL context gives access to all the public SQL functions and implicit conversions.</span>
<span class="hljs-keyword">import</span> hiveContext._

hql(<span class="hljs-string">"CREATE TABLE IF NOT EXISTS src (key INT, value STRING)"</span>)
hql(<span class="hljs-string">"LOAD DATA LOCAL INPATH 'examples/src/main/resources/kv1.txt' INTO TABLE src"</span>)

<span class="hljs-comment">// Queries are expressed in HiveQL</span>
hql(<span class="hljs-string">"FROM src SELECT key, value"</span>).collect().foreach(println)
hql(<span class="hljs-string">"drop table src"</span>)
</code></pre>
<p>create操作会在<strong>/user/hive/warehouse/</strong>目录下创建src目录，可以用以下指令来验证</p>
<pre><code class="bash hljs ">$<span class="hljs-variable">$HADOOP_HOME</span>/bin/hdfs dfs -ls /user/hive/warehouse/
</code></pre>
<p>&nbsp;drop表的时候，<span style="color: #ff0000;"><strong>不仅metastore中相应的记录被删除，而且原始数据raw file本身也会被删除</strong></span>，即在warehouse目录下对应某个表的目录会被整体删除掉。</p>
<p>上述的create, load及query操作对metastore和raw data的影响可以用下图的表示</p>
<p><img style="display: block; margin-left: auto; margin-right: auto;" src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/041036076142815.png" alt=""></p>
<h3>hive-site.xml</h3>
<p>如果想对hive默认的配置作修改，可以使用hive-site.xml。</p>
<p>具体步骤如下</p>
<p>&nbsp;-&nbsp; 在$SPARK_HOME/conf目录下创建hive-site.xml</p>
<p>&nbsp;-&nbsp; 根据需要，添写相应的配置项的值，可以这样做，将<strong>$HIVE_HOME/conf</strong>目录下的<strong>hive-default.xml</strong>复制到$SPARK_HOME/conf，然后重命名为<strong>hive-site.xml</strong></p>
<h2>Sql新功能预告</h2>
<p>为了进一步提升sql的执行速度，在Spark开发团队在发布完1.0之后，会通过codegen的方法来提升执行速度。codegen有点类似于jvm中的jit技术。充分利用了scala语言的特性。</p>
<h1>前景分析</h1>
<p>Spark目前还缺乏一个非常有影响力的应用，也就通常所说的killer application。SQL是Spark在寻找killer application方面所做的一个积极尝试，也是目前Spark上最有热度的一个话题，<span style="color: #ff0000;"><strong>但通过优化Hive执行速度来吸引潜在Spark用户，该突破方向选择正确与否还有待市场证明。</strong></span></p>
<p>Hive除了在执行速度上为人诟病之外，还有一个最大的问题就是多用户访问的问题，相较第一个问题，第二个问题来得更为致命。无论是Facebook在Hive之后推出的Presto还是Cloudera推出的Impala都是针对第二问题提出的解决方案，目前都已经取得的了巨大优势。</p>
<h1>小结</h1>
<p>本文就Spark对HiveQL提供支持的这一功能进行了比较详细的分析，其中涉及到以下几个问题。</p>
<ol>
<li>什么是hive</li>
<li>hive有什么缺点，否则就没Spark或Shark啥事了</li>
<li>Spark主要是针对hive的哪个不足做出改进</li>
<li>Spark是如何对这个做改进的</li>
</ol>
<h1>参考资料</h1>
<ol>
<li>programming hive</li>
<li><a href="https://groups.google.com/forum/#!topic/spark-users/PJj5HPt8m2o">Shark vs. Impala</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/Design#Design-HiveArchitecture">Hive Design</a></li>
</ol></div><div id="MySignature"></div>
<div class="clear"></div>
<div id="blog_post_info_block">
<div id="BlogPostCategory">分类: <a href="http://www.cnblogs.com/hseagle/category/569175.html">Apache Spark</a></div>
<div id="EntryTag">标签: <a href="http://www.cnblogs.com/hseagle/tag/Apache%20Spark/">Apache Spark</a>, <a href="http://www.cnblogs.com/hseagle/tag/Hive/">Hive</a></div>
<div id="blog_post_info"><div id="green_channel">
<a href="javascript:void(0);" id="green_channel_digg" onclick="DiggIt(3765207,cb_blogId,1);green_channel_success(this,&#39;谢谢推荐！&#39;);">好文要顶</a>
<a id="green_channel_follow" onclick="c_follow();" href="javascript:void(0);">关注我</a>
<a id="green_channel_favorite" onclick="AddToWz(cb_entryId);return false;" href="javascript:void(0);">收藏该文</a><a id="green_channel_contact" href="http://msg.cnblogs.com/send/%E5%BE%BD%E6%B2%AA%E4%B8%80%E9%83%8E" target="_blank">联系我</a>
<a id="green_channel_weibo" href="javascript:void(0);" title="分享至新浪微博" onclick="ShareToTsina()"><img src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/icon_weibo_24.png" alt=""></a>
<a id="green_channel_wechat" href="javascript:void(0);" title="分享至微信" onclick="shareOnWechat()"><img src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/wechat.png" alt=""></a>
</div>
<div id="author_profile">
<div id="author_profile_info" class="author_profile_info">
<a href="http://home.cnblogs.com/u/hseagle/" target="_blank"><img src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/sample_face.gif" class="author_avatar" alt=""></a>
<div id="author_profile_detail" class="author_profile_info">
<a href="http://home.cnblogs.com/u/hseagle/">徽沪一郎</a><br>
<a href="http://home.cnblogs.com/u/hseagle/followees">关注 - 5</a><br>
<a href="http://home.cnblogs.com/u/hseagle/followers">粉丝 - 193</a>
</div>
</div>
<div class="clear"></div>
<div id="author_profile_honor"></div>
<div id="author_profile_follow">
    <a href="javascript:void(0);" onclick="c_follow();return false;">+加关注</a>
</div>
</div>
<div id="div_digg">										
    <div class="diggit" onclick="votePost(3765207,&#39;Digg&#39;)">
        <span class="diggnum" id="digg_count">0</span>
    </div>
	<div class="buryit" onclick="votePost(3765207,&#39;Bury&#39;)"> 
		<span class="burynum" id="bury_count">0</span>
	</div>
	<div class="clear"></div>	
	<div class="diggword" id="digg_tips">
    (请您对文章做出评价)
    </div>	
</div>
</div>
<div class="clear"></div>
<div id="post_next_prev"><a href="http://www.cnblogs.com/hseagle/p/3758922.html" class="p_n_p_prefix">« </a> 上一篇：<a href="http://www.cnblogs.com/hseagle/p/3758922.html" title="发布于2014-05-30 08:44">Apache Spark源码走读之12 -- Hive on Spark运行环境搭建</a><br><a href="http://www.cnblogs.com/hseagle/p/3777494.html" class="p_n_p_prefix">» </a> 下一篇：<a href="http://www.cnblogs.com/hseagle/p/3777494.html" title="发布于2014-06-11 11:01">Apache Spark源码走读之14 -- Graphx实现剖析</a><br></div>
</div>


		</div>
		<div class="postDesc">posted @ <span id="post-date">2014-06-04 11:19</span> <a href="http://www.cnblogs.com/hseagle/">徽沪一郎</a> 阅读(<span id="post_view_count">3065</span>) 评论(<span id="post_comment_count">1</span>)  <a href="http://i.cnblogs.com/EditPosts.aspx?postid=3765207" rel="nofollow">编辑</a> <a href="http://www.cnblogs.com/hseagle/p/3765207.html#" onclick="AddToWz(3765207);return false;">收藏</a></div>
	</div>
	<script type="text/javascript">var allowComments=true,isLogined=false,cb_blogId=134061,cb_entryId=3765207,cb_blogApp=currentBlogApp,cb_blogUserGuid='8f4525b4-4a31-e211-aa8f-842b2b196315',cb_entryCreatedDate='2014/6/4 11:19:00';loadViewCount(cb_entryId);</script>
	
</div><!--end: topics 文章、评论容器-->
</div><a name="!comments"></a><div id="blog-comments-placeholder"><div id="comments_pager_top"></div>
<!--done-->
<div class="feedback_area_title">评论列表</div>
<div class="feedbackNoItems"></div>
	

		<div class="feedbackItem">
			<div class="feedbackListSubtitle">
				<div class="feedbackManage">
					&nbsp;&nbsp;<span class="comment_actions"></span>
				</div>
				<a href="http://www.cnblogs.com/hseagle/p/3765207.html#2979848" class="layer">#1楼</a><a name="2979848" id="comment_anchor_2979848"></a><span id="comment-maxId" style="display:none;">2979848</span><span id="comment-maxDate" style="display:none;">2014/7/9 10:23:06</span>  <span class="comment_date">2014-07-09 10:23</span> <a id="a_comment_author_2979848" href="http://home.cnblogs.com/u/647936/" target="_blank">jackyhung</a> <a href="http://msg.cnblogs.com/send/jackyhung" title="发送站内短消息" class="sendMsg2This">&nbsp;</a>
			</div>
			<div class="feedbackCon">
				<div id="comment_body_2979848" class="blog_comment_body">如何运行现有的基于hive的UDF呢？<br><br>比如在sparkshell里：<br><br>hql("CREATE TEMPORARY FUNCTION t_ts AS 'udf.Timestamp'")<br><br>然后<br>hql("select t_ts(time) from data where xxxx limit 1").collect().foreach(println)<br><br>就遇到了<br>java.lang.NullPointerException at org.apache.spark.sql.hive.HiveFunctionFactory$class.getFunctionClass(hiveUdfs.scala:117)<br><br>当不同udf执行sql，结果正常。<br><br>不知道是否应该这样引入UDF的定义<br><br><br>盼回复，thanks</div><div class="comment_vote"><a href="javascript:void(0);" class="comment_digg" onclick="return voteComment(2979848,&#39;Digg&#39;,this)">支持(0)</a><a href="javascript:void(0);" class="comment_bury" onclick="return voteComment(2979848,&#39;Bury&#39;,this)">反对(0)</a></div>
			</div>
		</div>
	<div id="comments_pager_bottom"></div></div><script type="text/javascript">var commentManager = new blogCommentManager();commentManager.renderComments(0);</script>
<div id="comment_form" class="commentform">
<a name="commentform"></a>
<div id="divCommentShow"></div>
<div id="comment_nav"><span id="span_refresh_tips"></span><a href="javascript:void(0);" onclick="return RefreshCommentList();" id="lnk_RefreshComments" runat="server" clientidmode="Static">刷新评论</a><a href="http://www.cnblogs.com/hseagle/p/3765207.html#" onclick="return RefreshPage();">刷新页面</a><a href="http://www.cnblogs.com/hseagle/p/3765207.html#top">返回顶部</a></div>
<div id="comment_form_container"><div class="login_tips">注册用户登录后才能发表评论，请 <a rel="nofollow" href="javascript:void(0);" class="underline" onclick="return login(&#39;commentform&#39;);">登录</a> 或 <a rel="nofollow" href="javascript:void(0);" class="underline" onclick="return register();">注册</a>，<a href="http://www.cnblogs.com/">访问</a>网站首页。</div></div>
<div class="ad_text_commentbox" id="ad_text_under_commentbox"></div>
<div id="ad_t2"><a href="http://www.ucancode.com/index.htm" target="_blank">【推荐】50万行VC++源码: 大型组态工控、电力仿真CAD与GIS源码库</a><br><a href="https://www.jpush.cn/" target="_blank">【推荐】极光推送30多万开发者的选择，SDK接入量超过30亿了，你还没注册？</a><br><a href="http://click.aliyun.com/m/3037/" target="_blank">【阿里云SSD云盘】速度行业领先</a><br></div>
<div id="opt_under_post"></div>
<div id="ad_c1" class="c_ad_block"><a href="http://www.cnblogs.com/onepixel/p/5062456.html" target="_blank"><img width="300" height="250" src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/explain-it-simply.jpg" alt="explain it simply" title="explain it simply"></a></div>
<div id="under_post_news"><div class="itnews c_ad_block"><b>最新IT新闻</b>:<br> ·  <a href="http://news.cnblogs.com/n/536909/" target="_blank">别拿高频低频瞎忽悠，让O2O们死个明白</a><br> ·  <a href="http://news.cnblogs.com/n/536908/" target="_blank">阿里健康新年第一步 建公益寻药平台</a><br> ·  <a href="http://news.cnblogs.com/n/536907/" target="_blank">微软宣布Build 2016门票开售时间 及Microsoft Envision</a><br> ·  <a href="http://news.cnblogs.com/n/536906/" target="_blank">像李彦宏这样沉沦，还是像马化腾这样革命？</a><br> ·  <a href="http://news.cnblogs.com/n/536905/" target="_blank">A站完成软银中国6000万A轮融资并更换CEO</a><br>» <a href="http://news.cnblogs.com/" title="IT新闻" target="_blank">更多新闻...</a></div></div>
<div id="under_post_kb"><div class="itnews c_ad_block" id="kb_block"><b>最新知识库文章</b>:<br><div id="kb_recent"> ·  <a href="http://kb.cnblogs.com/page/536387/" target="_blank">Docker简介</a><br> ·  <a href="http://kb.cnblogs.com/page/536115/" target="_blank">Docker简明教程</a><br> ·  <a href="http://kb.cnblogs.com/page/535581/" target="_blank">Git协作流程</a><br> ·  <a href="http://kb.cnblogs.com/page/535355/" target="_blank">企业计算的终结</a><br> ·  <a href="http://kb.cnblogs.com/page/535278/" target="_blank">软件开发的核心</a><br></div>» <a href="http://kb.cnblogs.com/" target="_blank">更多知识库文章...</a></div></div>
<div id="HistoryToday" class="c_ad_block"></div>
<script type="text/javascript">
$(function () {
    setTimeout(function () { incrementViewCount(cb_entryId); }, 50);
    deliverAdT2();
    deliverAdC1();    
    loadNewsAndKb();
    loadBlogSignature();
    LoadPostInfoBlock(cb_blogId, cb_entryId, cb_blogApp, cb_blogUserGuid);
    GetPrevNextPost(cb_entryId, cb_blogId, cb_entryCreatedDate);
    loadOptUnderPost();
    GetHistoryToday(cb_blogId, cb_blogApp, cb_entryCreatedDate);    
});
</script>
</div>


	</div><!--end: forFlow -->
	</div><!--end: mainContent 主体内容容器-->

	<div id="sideBar">
		<div id="sideBarMain">
			
<!--done-->
<div class="newsItem">
<h3 class="catListTitle">公告</h3>
	<div id="blog-news"><p>邮箱: hs_xp@163.com<br>
</p>
<p>QQ: 58506256&nbsp; <br>
</p>
<p>QQ群: Spark零基础学习 367106111</p>
<a target="_blank" href="http://shang.qq.com/wpa/qunwpa?idkey=99253f4f95c7f17a8d77d6cf2acfacfa6556ae645d22f9c6a13d24142341761e"><img src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/group.png" alt="Spark零基础学习" title="Spark零基础学习" border="0"></a>
<br>
<p>&nbsp;</p>
<embed src="http://service.weibo.com/staticjs/weiboshow.swf?verifier=8feb07ed&amp;uid=2060926175&amp;width=200&amp;height=500&amp;fansRow=2&amp;isTitle=1&amp;isWeibo=1&amp;isFans=1&amp;noborder=0&amp;ptype=1&amp;colors=cfe1f3,fafcff,444444,5093d5" quality="high" scale="noborder" align="L" height="500" width="200"><div id="profile_block">昵称：<a href="http://home.cnblogs.com/u/hseagle/">徽沪一郎</a><br>园龄：<a href="http://home.cnblogs.com/u/hseagle/" title="入园时间：2012-11-18">3年1个月</a><br>粉丝：<a href="http://home.cnblogs.com/u/hseagle/followers/">193</a><br>关注：<a href="http://home.cnblogs.com/u/hseagle/followees/">5</a><div id="p_b_follow"><a href="javascript:void(0);" onclick="cnblogs.UserManager.FollowBlogger(&#39;8f4525b4-4a31-e211-aa8f-842b2b196315&#39;)">+加关注</a></div></div></div><script type="text/javascript">loadBlogNews();</script>
</div>

			<div id="calendar"><div id="blog-calendar" style=""><table id="blogCalendar" class="Cal" cellspacing="0" cellpadding="0" title="Calendar">
	<tbody><tr><td colspan="7"><table class="CalTitle" cellspacing="0">
		<tbody><tr><td class="CalNextPrev"><a href="javascript:void(0);" onclick="loadBlogCalendar(&#39;2015/12/01&#39;);return false;">&lt;</a></td><td align="center">2016年1月</td><td class="CalNextPrev" align="right"><a href="javascript:void(0);" onclick="loadBlogCalendar(&#39;2016/02/01&#39;);return false;">&gt;</a></td></tr>
	</tbody></table></td></tr><tr><th class="CalDayHeader" align="center" abbr="日" scope="col">日</th><th class="CalDayHeader" align="center" abbr="一" scope="col">一</th><th class="CalDayHeader" align="center" abbr="二" scope="col">二</th><th class="CalDayHeader" align="center" abbr="三" scope="col">三</th><th class="CalDayHeader" align="center" abbr="四" scope="col">四</th><th class="CalDayHeader" align="center" abbr="五" scope="col">五</th><th class="CalDayHeader" align="center" abbr="六" scope="col">六</th></tr><tr><td class="CalOtherMonthDay" align="center">27</td><td class="CalOtherMonthDay" align="center">28</td><td class="CalOtherMonthDay" align="center">29</td><td class="CalOtherMonthDay" align="center">30</td><td class="CalOtherMonthDay" align="center">31</td><td align="center">1</td><td class="CalWeekendDay" align="center">2</td></tr><tr><td class="CalWeekendDay" align="center">3</td><td align="center">4</td><td align="center">5</td><td align="center">6</td><td align="center"><a href="http://www.cnblogs.com/hseagle/archive/2016/01/07.html"><u>7</u></a></td><td align="center">8</td><td class="CalWeekendDay" align="center">9</td></tr><tr><td class="CalWeekendDay" align="center">10</td><td align="center">11</td><td align="center">12</td><td align="center">13</td><td class="CalTodayDay" align="center">14</td><td align="center">15</td><td class="CalWeekendDay" align="center">16</td></tr><tr><td class="CalWeekendDay" align="center">17</td><td align="center">18</td><td align="center">19</td><td align="center">20</td><td align="center">21</td><td align="center">22</td><td class="CalWeekendDay" align="center">23</td></tr><tr><td class="CalWeekendDay" align="center">24</td><td align="center">25</td><td align="center">26</td><td align="center">27</td><td align="center">28</td><td align="center">29</td><td class="CalWeekendDay" align="center">30</td></tr><tr><td class="CalWeekendDay" align="center">31</td><td class="CalOtherMonthDay" align="center">1</td><td class="CalOtherMonthDay" align="center">2</td><td class="CalOtherMonthDay" align="center">3</td><td class="CalOtherMonthDay" align="center">4</td><td class="CalOtherMonthDay" align="center">5</td><td class="CalOtherMonthDay" align="center">6</td></tr>
</tbody></table></div><script type="text/javascript">loadBlogDefaultCalendar();</script></div>
			
			<div id="leftcontentcontainer">
				<div id="blog-sidecolumn"><div id="sidebar_search" class="sidebar-block">
<div id="sidebar_search" class="mySearch">
<h3 class="catListTitle">搜索</h3>
<div id="sidebar_search_box">
<div id="widget_my_zzk" class="div_my_zzk"><input type="text" id="q" onkeydown="return zzk_go_enter(event);" class="input_my_zzk">&nbsp;<input onclick="zzk_go()" type="button" value="找找看" id="btnZzk" class="btn_my_zzk"></div>

</div>
</div>

</div><div id="sidebar_categories">
<div class="catListPostCategory">
<h3 class="catListTitle">随笔分类<span style="font-size:11px;font-weight:normal">(70)</span></h3>

<ul>

<li><a id="CatList_LinkList_0_Link_0" href="http://www.cnblogs.com/hseagle/category/569175.html">Apache Spark(34)</a> </li>

<li><a id="CatList_LinkList_0_Link_1" href="http://www.cnblogs.com/hseagle/category/519033.html">Apache Storm(16)</a> </li>

<li><a id="CatList_LinkList_0_Link_2" href="http://www.cnblogs.com/hseagle/category/514458.html">archlinux(1)</a> </li>

<li><a id="CatList_LinkList_0_Link_3" href="http://www.cnblogs.com/hseagle/category/664228.html">BigData(1)</a> </li>

<li><a id="CatList_LinkList_0_Link_4" href="http://www.cnblogs.com/hseagle/category/565169.html">Database(1)</a> </li>

<li><a id="CatList_LinkList_0_Link_5" href="http://www.cnblogs.com/hseagle/category/759340.html">Elasticsearch(2)</a> </li>

<li><a id="CatList_LinkList_0_Link_6" href="http://www.cnblogs.com/hseagle/category/470583.html">GDB(9)</a> </li>

<li><a id="CatList_LinkList_0_Link_7" href="http://www.cnblogs.com/hseagle/category/554058.html">Hadoop(3)</a> </li>

<li><a id="CatList_LinkList_0_Link_8" href="http://www.cnblogs.com/hseagle/category/519017.html">memory management(1)</a> </li>

<li><a id="CatList_LinkList_0_Link_9" href="http://www.cnblogs.com/hseagle/category/646056.html">Scala(2)</a> </li>

</ul>

</div>

<div class="catListPostArchive">
<h3 class="catListTitle">随笔档案<span style="font-size:11px;font-weight:normal">(76)</span></h3>

<ul>

<li><a id="CatList_LinkList_1_Link_0" href="http://www.cnblogs.com/hseagle/archive/2016/01.html">2016年1月 (1)</a> </li>

<li><a id="CatList_LinkList_1_Link_1" href="http://www.cnblogs.com/hseagle/archive/2015/11.html">2015年11月 (1)</a> </li>

<li><a id="CatList_LinkList_1_Link_2" href="http://www.cnblogs.com/hseagle/archive/2015/04.html">2015年4月 (1)</a> </li>

<li><a id="CatList_LinkList_1_Link_3" href="http://www.cnblogs.com/hseagle/archive/2015/03.html">2015年3月 (1)</a> </li>

<li><a id="CatList_LinkList_1_Link_4" href="http://www.cnblogs.com/hseagle/archive/2015/02.html">2015年2月 (1)</a> </li>

<li><a id="CatList_LinkList_1_Link_5" href="http://www.cnblogs.com/hseagle/archive/2015/01.html">2015年1月 (2)</a> </li>

<li><a id="CatList_LinkList_1_Link_6" href="http://www.cnblogs.com/hseagle/archive/2014/12.html">2014年12月 (1)</a> </li>

<li><a id="CatList_LinkList_1_Link_7" href="http://www.cnblogs.com/hseagle/archive/2014/11.html">2014年11月 (1)</a> </li>

<li><a id="CatList_LinkList_1_Link_8" href="http://www.cnblogs.com/hseagle/archive/2014/10.html">2014年10月 (1)</a> </li>

<li><a id="CatList_LinkList_1_Link_9" href="http://www.cnblogs.com/hseagle/archive/2014/09.html">2014年9月 (4)</a> </li>

<li><a id="CatList_LinkList_1_Link_10" href="http://www.cnblogs.com/hseagle/archive/2014/08.html">2014年8月 (5)</a> </li>

<li><a id="CatList_LinkList_1_Link_11" href="http://www.cnblogs.com/hseagle/archive/2014/07.html">2014年7月 (4)</a> </li>

<li><a id="CatList_LinkList_1_Link_12" href="http://www.cnblogs.com/hseagle/archive/2014/06.html">2014年6月 (4)</a> </li>

<li><a id="CatList_LinkList_1_Link_13" href="http://www.cnblogs.com/hseagle/archive/2014/05.html">2014年5月 (9)</a> </li>

<li><a id="CatList_LinkList_1_Link_14" href="http://www.cnblogs.com/hseagle/archive/2014/04.html">2014年4月 (6)</a> </li>

<li><a id="CatList_LinkList_1_Link_15" href="http://www.cnblogs.com/hseagle/archive/2014/03.html">2014年3月 (1)</a> </li>

<li><a id="CatList_LinkList_1_Link_16" href="http://www.cnblogs.com/hseagle/archive/2014/02.html">2014年2月 (4)</a> </li>

<li><a id="CatList_LinkList_1_Link_17" href="http://www.cnblogs.com/hseagle/archive/2014/01.html">2014年1月 (4)</a> </li>

<li><a id="CatList_LinkList_1_Link_18" href="http://www.cnblogs.com/hseagle/archive/2013/12.html">2013年12月 (3)</a> </li>

<li><a id="CatList_LinkList_1_Link_19" href="http://www.cnblogs.com/hseagle/archive/2013/11.html">2013年11月 (3)</a> </li>

<li><a id="CatList_LinkList_1_Link_20" href="http://www.cnblogs.com/hseagle/archive/2013/10.html">2013年10月 (1)</a> </li>

<li><a id="CatList_LinkList_1_Link_21" href="http://www.cnblogs.com/hseagle/archive/2013/09.html">2013年9月 (7)</a> </li>

<li><a id="CatList_LinkList_1_Link_22" href="http://www.cnblogs.com/hseagle/archive/2013/08.html">2013年8月 (1)</a> </li>

<li><a id="CatList_LinkList_1_Link_23" href="http://www.cnblogs.com/hseagle/archive/2013/06.html">2013年6月 (1)</a> </li>

<li><a id="CatList_LinkList_1_Link_24" href="http://www.cnblogs.com/hseagle/archive/2013/05.html">2013年5月 (2)</a> </li>

<li><a id="CatList_LinkList_1_Link_25" href="http://www.cnblogs.com/hseagle/archive/2013/04.html">2013年4月 (3)</a> </li>

<li><a id="CatList_LinkList_1_Link_26" href="http://www.cnblogs.com/hseagle/archive/2013/03.html">2013年3月 (4)</a> </li>

</ul>

</div>

</div><div id="sidebar_scorerank" class="sidebar-block">
<div class="catListBlogRank">
<h3 class="catListTitle">积分与排名</h3>
<ul>
	<li class="liScore">
		积分 -	104754
	</li>
	<li class="liRank">
		排名 -	1810
	</li>
</ul>
</div>


</div><div id="sidebar_topviewedposts" class="sidebar-block"><div id="topview_posts_wrap">
<div class="catListView">
<h3 class="catListTitle">阅读排行榜</h3>
	<div id="TopViewPostsBlock"><ul><li><a href="http://www.cnblogs.com/hseagle/p/3664933.html">1. Apache Spark源码走读之1 -- Spark论文阅读笔记(14197)</a></li><li><a href="http://www.cnblogs.com/hseagle/p/3673123.html">2. Apache Spark源码走读之2 -- Job的提交与运行(9805)</a></li><li><a href="http://www.cnblogs.com/hseagle/p/3673132.html">3. Apache Spark源码走读之3 -- Task运行期之函数调用关系分析(7388)</a></li><li><a href="http://www.cnblogs.com/hseagle/p/3850841.html">4. Apache Spark源码走读之18 -- 使用Intellij idea调试Spark源码(5476)</a></li><li><a href="http://www.cnblogs.com/hseagle/p/3756862.html">5. Apache Storm源码阅读笔记(4802)</a></li></ul></div>
</div>
</div></div><div id="sidebar_topcommentedposts" class="sidebar-block"><div id="topfeedback_posts_wrap">
<div class="catListFeedback">
<h3 class="catListTitle">评论排行榜</h3>
	<div id="TopFeedbackPostsBlock"><ul><li><a href="http://www.cnblogs.com/hseagle/p/3543782.html">1. Apache Storm 衍生项目之1 -- storm-yarn(5)</a></li><li><a href="http://www.cnblogs.com/hseagle/p/3732492.html">2. Apache Spark源码走读之9 -- Spark源码编译(4)</a></li><li><a href="http://www.cnblogs.com/hseagle/p/3664933.html">3. Apache Spark源码走读之1 -- Spark论文阅读笔记(4)</a></li><li><a href="http://www.cnblogs.com/hseagle/p/3850841.html">4. Apache Spark源码走读之18 -- 使用Intellij idea调试Spark源码(4)</a></li><li><a href="http://www.cnblogs.com/hseagle/p/3908276.html">5. Apache Spark源码走读之22 -- 浅谈mllib中线性回归的算法实现(3)</a></li></ul></div>
</div>
</div></div></div><script type="text/javascript">loadBlogSideColumn();</script><iframe src="./Apache Spark源码走读之13 -- hiveql on spark实现详解 - 徽沪一郎 - 博客园_files/container.html" style="visibility: hidden; display: none;"></iframe>
			</div>
			
		</div><!--end: sideBarMain -->
	</div><!--end: sideBar 侧边栏容器 -->
	<div class="clear"></div>
	</div><!--end: main -->
	<div class="clear"></div>
	<div id="footer">
		
<!--done-->
Copyright ©2016 徽沪一郎
	</div><!--end: footer -->
</div><!--end: home 自定义的最大容器 -->


</body></html>